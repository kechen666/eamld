{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dec7546f",
   "metadata": {},
   "source": [
    "# 分析解码图的拓扑结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f872a4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d & r & syndrome with data qubits & #nodes & #hyperedges & max hyperedge size \\\\ \\hline\n",
      "3 & 1 & True & 8 & 23 & 2 \\\\\n",
      "3 & 3 & True & 24 & 219 & 4 \\\\\n",
      "3 & 1 & False & 4 & 10 & 2 \\\\\n",
      "3 & 3 & False & 20 & 196 & 4 \\\\\n"
     ]
    }
   ],
   "source": [
    "from epmld.benchmark import generate_detector_error_model\n",
    "from epmld.contraction_strategy.dem_to_hypergraph import DetectorErrorModelHypergraph\n",
    "from epmld.contraction_strategy.hypergraph_to_connectivity import ConnectivityGraph\n",
    "\n",
    "\n",
    "related_path = \"/home/normaluser/ck/epmld/data/external/epmld_experiment_data/epmld_paper_experiment/noise_varying_threshold/surface_code\"\n",
    "\n",
    "save_path = \"/home/normaluser/ck/epmld/experiment/epmld_paper_experiment/figure/graph_topology\"\n",
    "\n",
    "code_tasks = [\"surface_code:rotated_memory_z\"]\n",
    "# \"surface_code:rotated_memory_x\",\n",
    "\n",
    "# distances = [3, 5, 7]\n",
    "distances = [3]\n",
    "probabilities = [10]\n",
    "\n",
    "noise_models = [\"si1000\"]\n",
    "have_stabilizers = [True, False]\n",
    "# have_stabilizers = [False]\n",
    "\n",
    "# decoder_methods = [\"MWPM\", \"EAMLD\"]\n",
    "\n",
    "decoder_methods = [\"EAMLD\"]\n",
    "\n",
    "print(\"d & r & syndrome with data qubits & #nodes & #hyperedges & max hyperedge size \\\\\\\\ \\\\hline\")\n",
    "\n",
    "for code_task in code_tasks:\n",
    "    error_type = \"Z\" if \"memory_z\" in code_task else \"X\" if \"memory_x\" in code_task else \"other\"\n",
    "    for have_stabilizer in have_stabilizers:\n",
    "        for d in distances:\n",
    "            for p in probabilities:\n",
    "                rounds = [1, d]\n",
    "                for r in rounds:\n",
    "                    for noise_model in noise_models:\n",
    "                        for decoder_method in decoder_methods:\n",
    "                            # 获取对应的检测器错误率模型，用于构建解码器\n",
    "                            if decoder_method == \"MWPM\":\n",
    "                                dem = generate_detector_error_model(d = d, r=r, p=p, noise_model=noise_model,\n",
    "                                                                    error_type=error_type, decomposed_error = True,\n",
    "                                                                    related_path=related_path, have_stabilizer = have_stabilizer)\n",
    "                            else:\n",
    "                                dem = generate_detector_error_model(d = d, r=r, p=p, noise_model=noise_model,\n",
    "                                                                    error_type=error_type, decomposed_error = False,\n",
    "                                                                    related_path=related_path, have_stabilizer = have_stabilizer)\n",
    "                            \n",
    "                            hypergraph = DetectorErrorModelHypergraph(detector_error_model= dem, have_logical_observable=False)\n",
    "                            # 计算超图的相关数据\n",
    "                            nodes = hypergraph.get_nodes()\n",
    "                            hyperedges = hypergraph.get_hyperedges()\n",
    "                            weights = hypergraph.get_weights()\n",
    "                            max_detectors_per_hyperedge = 0\n",
    "                            # 遍历所有超边\n",
    "                            for hyperedge in hyperedges:\n",
    "                                # 统计当前超边连接的检测器数量\n",
    "                                num_detectors = len(hyperedge)\n",
    "                                # 更新最大连接检测器数量\n",
    "                                max_detectors_per_hyperedge = max(max_detectors_per_hyperedge, num_detectors)\n",
    "                            \n",
    "                            print(f\"{d} & {r} & {have_stabilizer} & {len(nodes)} & {len(hyperedges)} & {max_detectors_per_hyperedge} \\\\\\\\\")\n",
    "                            \n",
    "                            # # 保存d=3,r=1和d=5,r=1的连通性图片为PDF\n",
    "                            if d in [3,5] and r==1:\n",
    "                                connectivity_graph = ConnectivityGraph()\n",
    "                                connectivity_graph.hypergraph_to_connectivity_graph(hypergraph)\n",
    "                                connectivity_graph.draw(\"spring\", save_path + \"/\"+ f\"Connectivity Graph - d is {d}, r is {r}, Syndrome with Data Qubits is {have_stabilizer}.pdf\")\n",
    "                                # connectivity_graph.draw(\"spring\", save_path, f\"Connectivity Graph - d is {d}, r is {r}, Syndrome with Data Qubits is {have_stabilizer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01412698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nkd & r & syndrome with data qubits & #nodes & #hyperedges & max hyperedge size \\\\ \\hline\n",
      "[72, 12, 6] & 1 & True & 72 & 432 & 6 \\\\\n",
      "[72, 12, 6] & 6 & True & 432 & 16164 & 9 \\\\\n",
      "[144, 12, 12] & 1 & True & 144 & 864 & 6 \\\\\n",
      "[144, 12, 12] & 12 & True & 1728 & 67752 & 9 \\\\\n",
      "[72, 12, 6] & 1 & False & 36 & 332 & 3 \\\\\n",
      "[72, 12, 6] & 6 & False & 396 & 15932 & 9 \\\\\n",
      "[144, 12, 12] & 1 & False & 72 & 617 & 3 \\\\\n",
      "[144, 12, 12] & 12 & False & 1656 & 67366 & 9 \\\\\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "from epmld.benchmark import generate_qldpc_detector_error_model\n",
    "from epmld.contraction_strategy.dem_to_hypergraph import DetectorErrorModelHypergraph\n",
    "from epmld.contraction_strategy.hypergraph_to_connectivity import ConnectivityGraph\n",
    "\n",
    "\n",
    "related_path = \"/home/normaluser/ck/epmld/data/external/epmld_experiment_data/epmld_paper_experiment/noise_varying_threshold/qldpc_code\"\n",
    "\n",
    "save_path = \"/home/normaluser/ck/epmld/experiment/epmld_paper_experiment/figure/graph_topology\"\n",
    "\n",
    "# code_tasks = [\"surface_code:rotated_memory_z\"]\n",
    "code_tasks = [ \"bivariate_bicycle_code:rotated_memory_z\"]\n",
    "# \"bivariate_bicycle_code:rotated_memory_x\",\n",
    "# \"surface_code:rotated_memory_x\",\n",
    "\n",
    "# nkds = [3, 5, 7]\n",
    "nkds = [[72, 12, 6], [144, 12, 12]]\n",
    "# distances = [5]\n",
    "probabilities = [10]\n",
    "\n",
    "noise_models = [\"si1000\"]\n",
    "have_stabilizers = [True, False]\n",
    "\n",
    "# decoder_methods = [\"MWPM\", \"EAMLD\"]\n",
    "\n",
    "decoder_methods = [\"EAMLD\"]\n",
    "\n",
    "print(\"nkd & r & syndrome with data qubits & #nodes & #hyperedges & max hyperedge size \\\\\\\\ \\\\hline\")\n",
    "\n",
    "for code_task in code_tasks:\n",
    "    error_type = \"Z\" if \"memory_z\" in code_task else \"X\" if \"memory_x\" in code_task else \"other\"\n",
    "    for have_stabilizer in have_stabilizers:\n",
    "        for nkd in nkds:\n",
    "            for p in probabilities:\n",
    "                d = nkd[2]\n",
    "                rounds = [1, d]\n",
    "                for r in rounds:\n",
    "                    for noise_model in noise_models:\n",
    "                        for decoder_method in decoder_methods:\n",
    "                            # 获取对应的检测器错误率模型，用于构建解码器\n",
    "                            dem = generate_qldpc_detector_error_model(nkd=nkd, r=r, p=p, noise_model=noise_model, \n",
    "                                                                    error_type=error_type,related_path=related_path,\n",
    "                                                                    have_stabilizer = have_stabilizer)\n",
    "                            \n",
    "                            hypergraph = DetectorErrorModelHypergraph(detector_error_model= dem, have_logical_observable=False)\n",
    "                            # 计算超图的相关数据\n",
    "                            nodes = hypergraph.get_nodes()\n",
    "                            hyperedges = hypergraph.get_hyperedges()\n",
    "                            weights = hypergraph.get_weights()\n",
    "                            max_detectors_per_hyperedge = 0\n",
    "                            # 遍历所有超边\n",
    "                            for hyperedge in hyperedges:\n",
    "                                # 统计当前超边连接的检测器数量\n",
    "                                num_detectors = len(hyperedge)\n",
    "                                # 更新最大连接检测器数量\n",
    "                                max_detectors_per_hyperedge = max(max_detectors_per_hyperedge, num_detectors)\n",
    "                            \n",
    "                            print(f\"{nkd} & {r} & {have_stabilizer} & {len(nodes)} & {len(hyperedges)} & {max_detectors_per_hyperedge} \\\\\\\\\")\n",
    "                            \n",
    "                            # # 保存d=3,r=1和d=5,r=1的连通性图片为PDF\n",
    "                            if nkd == [72, 12, 6] and r==1:\n",
    "                                connectivity_graph = ConnectivityGraph()\n",
    "                                connectivity_graph.hypergraph_to_connectivity_graph(hypergraph)\n",
    "                                connectivity_graph.draw(\"spring\", save_path + \"/\"+ f\"Connectivity Graph - nkd is {nkd}, r is {r}, Syndrome with Data Qubits is {have_stabilizer}.pdf\")\n",
    "                                # connectivity_graph.draw(\"spring\", save_path, f\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ck_epmld",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
